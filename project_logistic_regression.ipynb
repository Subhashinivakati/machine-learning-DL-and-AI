{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a6c635",
   "metadata": {},
   "source": [
    "## Step 1: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7261e530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Attendance_Percentage</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Study_Hours</th>\n",
       "      <th>Health_Status</th>\n",
       "      <th>School_Type</th>\n",
       "      <th>Study_Methods</th>\n",
       "      <th>Pass/Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lakshmi</td>\n",
       "      <td>81</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Stressed</td>\n",
       "      <td>Government</td>\n",
       "      <td>Group study</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rohan</td>\n",
       "      <td>92</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Private</td>\n",
       "      <td>YouTube videos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Priya</td>\n",
       "      <td>51</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Government</td>\n",
       "      <td>Books only</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ananya</td>\n",
       "      <td>49</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Stressed</td>\n",
       "      <td>Government</td>\n",
       "      <td>Ratta + coaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kiran</td>\n",
       "      <td>41</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Stressed</td>\n",
       "      <td>Private</td>\n",
       "      <td>Online tests</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Aarav</td>\n",
       "      <td>78</td>\n",
       "      <td>71.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Stressed</td>\n",
       "      <td>Private</td>\n",
       "      <td>Notes + revision</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Vikas</td>\n",
       "      <td>61</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Stressed</td>\n",
       "      <td>Government</td>\n",
       "      <td>Masti ðŸ˜‚</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Ananya</td>\n",
       "      <td>90</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Stressed</td>\n",
       "      <td>Government</td>\n",
       "      <td>Parent's guidance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Arjun</td>\n",
       "      <td>94</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doubt clearing sessions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Arjun</td>\n",
       "      <td>101</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Stressed</td>\n",
       "      <td>Private</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Attendance_Percentage  Midterm_Score  Study_Hours Health_Status  \\\n",
       "0    Lakshmi                     81           67.0            5      Stressed   \n",
       "1      Rohan                     92           72.0            6       Healthy   \n",
       "2      Priya                     51           41.0           12       Healthy   \n",
       "3     Ananya                     49           59.0            3      Stressed   \n",
       "4      Kiran                     41           87.0            1      Stressed   \n",
       "..       ...                    ...            ...          ...           ...   \n",
       "145    Aarav                     78           71.0            6      Stressed   \n",
       "146    Vikas                     61           24.0            5      Stressed   \n",
       "147   Ananya                     90           72.0           10      Stressed   \n",
       "148    Arjun                     94           44.0            7       Healthy   \n",
       "149    Arjun                    101           34.0            4      Stressed   \n",
       "\n",
       "    School_Type            Study_Methods  Pass/Fail  \n",
       "0    Government              Group study          1  \n",
       "1       Private           YouTube videos          1  \n",
       "2    Government               Books only          1  \n",
       "3    Government         Ratta + coaching          1  \n",
       "4       Private             Online tests          1  \n",
       "..          ...                      ...        ...  \n",
       "145     Private         Notes + revision          1  \n",
       "146  Government                  Masti ðŸ˜‚          1  \n",
       "147  Government        Parent's guidance          1  \n",
       "148     Private  Doubt clearing sessions          0  \n",
       "149     Private                     None          0  \n",
       "\n",
       "[150 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"student_performance_150.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "292f3509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (150, 8)\n",
      "\n",
      "First 5 rows:\n",
      "      Name  Attendance_Percentage  Midterm_Score  Study_Hours Health_Status  \\\n",
      "0  Lakshmi                     81           67.0            5      Stressed   \n",
      "1    Rohan                     92           72.0            6       Healthy   \n",
      "2    Priya                     51           41.0           12       Healthy   \n",
      "3   Ananya                     49           59.0            3      Stressed   \n",
      "4    Kiran                     41           87.0            1      Stressed   \n",
      "\n",
      "  School_Type     Study_Methods  Pass/Fail  \n",
      "0  Government       Group study          1  \n",
      "1     Private    YouTube videos          1  \n",
      "2  Government        Books only          1  \n",
      "3  Government  Ratta + coaching          1  \n",
      "4     Private      Online tests          1  \n"
     ]
    }
   ],
   "source": [
    "# Basic info\n",
    "print(\"Shape:\", df.shape)  # Should be (150, 8)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d55dd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "Name                      0\n",
      "Attendance_Percentage     0\n",
      "Midterm_Score            15\n",
      "Study_Hours               0\n",
      "Health_Status             0\n",
      "School_Type               0\n",
      "Study_Methods             0\n",
      "Pass/Fail                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "557e9270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics:\n",
      "         Name  Attendance_Percentage  Midterm_Score  Study_Hours  \\\n",
      "count     150             150.000000     135.000000   150.000000   \n",
      "unique     10                    NaN            NaN          NaN   \n",
      "top     Priya                    NaN            NaN          NaN   \n",
      "freq       19                    NaN            NaN          NaN   \n",
      "mean      NaN              70.613333      48.518519    24.686667   \n",
      "std       NaN              32.211088      20.228121   139.827465   \n",
      "min       NaN              -3.000000       3.000000    -4.000000   \n",
      "25%       NaN              47.250000      33.500000     3.000000   \n",
      "50%       NaN              69.000000      46.000000     5.000000   \n",
      "75%       NaN              91.000000      63.500000     7.000000   \n",
      "max       NaN             150.000000     116.000000  1000.000000   \n",
      "\n",
      "       Health_Status School_Type Study_Methods   Pass/Fail  \n",
      "count            150         150           150  150.000000  \n",
      "unique             2           2            10         NaN  \n",
      "top          Healthy     Private   Group study         NaN  \n",
      "freq              79          81            15         NaN  \n",
      "mean             NaN         NaN           NaN    0.640000  \n",
      "std              NaN         NaN           NaN    0.481608  \n",
      "min              NaN         NaN           NaN    0.000000  \n",
      "25%              NaN         NaN           NaN    0.000000  \n",
      "50%              NaN         NaN           NaN    1.000000  \n",
      "75%              NaN         NaN           NaN    1.000000  \n",
      "max              NaN         NaN           NaN    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe(include=\"all\"))  # Include categorical columns too"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d51c355",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42307b29",
   "metadata": {},
   "source": [
    "involves fixing missing values, handling outliers, and preparing text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d6e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Missing Values\n",
    ">> Midterm_Score has ~15 missing values, we cannot drop it. Impute missing values using mean or median\n",
    ">> Alternatively, drop rows if missing values are minimal (<5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b80b1706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing Midterm_Score with median\n",
    "df[\"Midterm_Score\"].fillna(df[\"Midterm_Score\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ff702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Outliers\n",
    "The IQR method identifies outliers based on quartiles:\n",
    "\n",
    "Q1 (25th percentile) : 25% of data points are â‰¤ Q1.\n",
    "Q3 (75th percentile) : 75% of data points are â‰¤ Q3.\n",
    "IQR = Q3 â€“ Q1 .\n",
    "Outlier bounds :\n",
    "Lower bound = Q1 â€“ 1.5 Ã— IQR\n",
    "Upper bound = Q3 + 1.5 Ã— IQR\n",
    "Any value outside these bounds is an outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "[10,12,14,15,16,18,20,22,24,25,100]\n",
    "\n",
    "values are sorted in ascending order.\n",
    "\n",
    "median (Q2) : The middle value is 18 .\n",
    "    \n",
    "Find Q1 : Median of the lower half (excluding Q2):\n",
    "Lower half = [10,12,14,15,16] â†’ Q1 = 14 .\n",
    "\n",
    "Find Q3 : Median of the upper half (excluding Q2):\n",
    "Upper half = [20,22,24,25,100] â†’ Q3 = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d291adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da7285e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Attendance_Percentage</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Study_Hours</th>\n",
       "      <th>Health_Status</th>\n",
       "      <th>School_Type</th>\n",
       "      <th>Study_Methods</th>\n",
       "      <th>Pass/Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Attendance_Percentage, Midterm_Score, Study_Hours, Health_Status, School_Type, Study_Methods, Pass/Fail]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detect outliers in \"Attendance_Percentage\"\n",
    "Q1 = df[\"Attendance_Percentage\"].quantile(0.25)\n",
    "Q3 = df[\"Attendance_Percentage\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter outliers\n",
    "outliers = df[(df[\"Attendance_Percentage\"] < lower_bound) | (df[\"Attendance_Percentage\"] > upper_bound)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61f0a342",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Detect Outliers Using Visualization\n",
    "\n",
    "# Boxplots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Boxplot for \"Attendance_Percentage\"\n",
    "sns.boxplot(x=df[\"Attendance_Percentage\"])\n",
    "plt.title(\"Attendance Percentage Outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ed5f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solutions for Handling Outliers\n",
    "\n",
    "# 1. Remove Outliers\n",
    "df_cleaned = df[(df[\"Attendance_Percentage\"] >= lower_bound) & (df[\"Attendance_Percentage\"] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "240705f4",
   "metadata": {},
   "outputs": [],
   "source": [
    " #2. Cap/Clip Values- Replace outliers with the nearest valid value \n",
    "df[\"Attendance_Percentage\"] = df[\"Attendance_Percentage\"].clip(lower=0, upper=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "models (e.g., Random Forest , XGBoost ) are less sensitive to outliers. so use them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4748e89d",
   "metadata": {},
   "source": [
    "## Step 3: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf387d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    ">> Handling Categorical Data : Encode categorical variables (e.g., Health_Status, School_Type) using techniques like label encoding or one-hot encoding.\n",
    ">> Creating New Features : Derive features from existing data (e.g., interaction terms like Attendance_Percentage Ã— Midterm_Score).\n",
    ">> Feature Scaling : Normalize/standardize numerical features (e.g., Study_Hours, Midterm_Score) to ensure equal contribution to the model. \n",
    ">> Text Vectorization : Convert text (Study_Methods) into numerical features using TF-IDF or word embeddings.\n",
    ">> Dimensionality Reduction : Use PCA or feature selection to reduce redundant or noisy features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c713833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical Encoding\n",
    "# Map categorical columns to numerical values\n",
    "df[\"Health_Status\"] = df[\"Health_Status\"].map({\"Healthy\": 0, \"Stressed\": 1})\n",
    "df[\"School_Type\"] = df[\"School_Type\"].map({\"Government\": 0, \"Private\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Standardization:\n",
    "    Transforms data to have a mean of 0 and a standard deviation of 1 (follows a standard normal distribution).\n",
    "\n",
    "Normalization (Min-Max Scaling)\n",
    "Definition : Rescales data to a fixed range (e.g., 0 to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcf0b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [\"Attendance_Percentage\", \"Midterm_Score\", \"Study_Hours\"]\n",
    "\n",
    "# Apply scaling\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c8f3782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Attendance_Percentage</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Study_Hours</th>\n",
       "      <th>Health_Status</th>\n",
       "      <th>School_Type</th>\n",
       "      <th>Study_Methods</th>\n",
       "      <th>Pass/Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lakshmi</td>\n",
       "      <td>0.529716</td>\n",
       "      <td>0.979070</td>\n",
       "      <td>-0.141264</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Group study</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rohan</td>\n",
       "      <td>0.949721</td>\n",
       "      <td>1.240388</td>\n",
       "      <td>-0.134089</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>YouTube videos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Priya</td>\n",
       "      <td>-0.615753</td>\n",
       "      <td>-0.379782</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Books only</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ananya</td>\n",
       "      <td>-0.692118</td>\n",
       "      <td>0.560962</td>\n",
       "      <td>-0.155615</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ratta + coaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kiran</td>\n",
       "      <td>-0.997576</td>\n",
       "      <td>2.024341</td>\n",
       "      <td>-0.169967</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Online tests</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Aarav</td>\n",
       "      <td>0.415169</td>\n",
       "      <td>1.188124</td>\n",
       "      <td>-0.134089</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Notes + revision</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Vikas</td>\n",
       "      <td>-0.233930</td>\n",
       "      <td>-1.268262</td>\n",
       "      <td>-0.141264</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Masti ðŸ˜‚</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Ananya</td>\n",
       "      <td>0.873356</td>\n",
       "      <td>1.240388</td>\n",
       "      <td>-0.105386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Parent's guidance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Arjun</td>\n",
       "      <td>1.026086</td>\n",
       "      <td>-0.222991</td>\n",
       "      <td>-0.126913</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Doubt clearing sessions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Arjun</td>\n",
       "      <td>1.255179</td>\n",
       "      <td>-0.745626</td>\n",
       "      <td>-0.148440</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Attendance_Percentage  Midterm_Score  Study_Hours  \\\n",
       "0    Lakshmi               0.529716       0.979070    -0.141264   \n",
       "1      Rohan               0.949721       1.240388    -0.134089   \n",
       "2      Priya              -0.615753      -0.379782    -0.091035   \n",
       "3     Ananya              -0.692118       0.560962    -0.155615   \n",
       "4      Kiran              -0.997576       2.024341    -0.169967   \n",
       "..       ...                    ...            ...          ...   \n",
       "145    Aarav               0.415169       1.188124    -0.134089   \n",
       "146    Vikas              -0.233930      -1.268262    -0.141264   \n",
       "147   Ananya               0.873356       1.240388    -0.105386   \n",
       "148    Arjun               1.026086      -0.222991    -0.126913   \n",
       "149    Arjun               1.255179      -0.745626    -0.148440   \n",
       "\n",
       "     Health_Status  School_Type            Study_Methods  Pass/Fail  \n",
       "0                1            0              Group study          1  \n",
       "1                0            1           YouTube videos          1  \n",
       "2                0            0               Books only          1  \n",
       "3                1            0         Ratta + coaching          1  \n",
       "4                1            1             Online tests          1  \n",
       "..             ...          ...                      ...        ...  \n",
       "145              1            1         Notes + revision          1  \n",
       "146              1            0                  Masti ðŸ˜‚          1  \n",
       "147              1            0        Parent's guidance          1  \n",
       "148              0            1  Doubt clearing sessions          0  \n",
       "149              1            1                     None          0  \n",
       "\n",
       "[150 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe30d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Name\",\"Study_Methods\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5af17de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attendance_Percentage</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Study_Hours</th>\n",
       "      <th>Health_Status</th>\n",
       "      <th>School_Type</th>\n",
       "      <th>Pass/Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.529716</td>\n",
       "      <td>0.979070</td>\n",
       "      <td>-0.141264</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.949721</td>\n",
       "      <td>1.240388</td>\n",
       "      <td>-0.134089</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.615753</td>\n",
       "      <td>-0.379782</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.692118</td>\n",
       "      <td>0.560962</td>\n",
       "      <td>-0.155615</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.997576</td>\n",
       "      <td>2.024341</td>\n",
       "      <td>-0.169967</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.415169</td>\n",
       "      <td>1.188124</td>\n",
       "      <td>-0.134089</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>-0.233930</td>\n",
       "      <td>-1.268262</td>\n",
       "      <td>-0.141264</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.873356</td>\n",
       "      <td>1.240388</td>\n",
       "      <td>-0.105386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1.026086</td>\n",
       "      <td>-0.222991</td>\n",
       "      <td>-0.126913</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.255179</td>\n",
       "      <td>-0.745626</td>\n",
       "      <td>-0.148440</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Attendance_Percentage  Midterm_Score  Study_Hours  Health_Status  \\\n",
       "0                 0.529716       0.979070    -0.141264              1   \n",
       "1                 0.949721       1.240388    -0.134089              0   \n",
       "2                -0.615753      -0.379782    -0.091035              0   \n",
       "3                -0.692118       0.560962    -0.155615              1   \n",
       "4                -0.997576       2.024341    -0.169967              1   \n",
       "..                     ...            ...          ...            ...   \n",
       "145               0.415169       1.188124    -0.134089              1   \n",
       "146              -0.233930      -1.268262    -0.141264              1   \n",
       "147               0.873356       1.240388    -0.105386              1   \n",
       "148               1.026086      -0.222991    -0.126913              0   \n",
       "149               1.255179      -0.745626    -0.148440              1   \n",
       "\n",
       "     School_Type  Pass/Fail  \n",
       "0              0          1  \n",
       "1              1          1  \n",
       "2              0          1  \n",
       "3              0          1  \n",
       "4              1          1  \n",
       "..           ...        ...  \n",
       "145            1          1  \n",
       "146            0          1  \n",
       "147            0          1  \n",
       "148            1          0  \n",
       "149            1          0  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b82ef",
   "metadata": {},
   "source": [
    "## Step 4: Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df41a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split Data into Train/Test Sets\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(\"Pass/Fail\", axis=1)\n",
    "y = df[\"Pass/Fail\"]\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb45ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Train a Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "685bffb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.57      1.00      0.72        17\n",
      "\n",
      "    accuracy                           0.57        30\n",
      "   macro avg       0.28      0.50      0.36        30\n",
      "weighted avg       0.32      0.57      0.41        30\n",
      "\n",
      "Random Forest Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.38      0.43        13\n",
      "           1       0.60      0.71      0.65        17\n",
      "\n",
      "    accuracy                           0.57        30\n",
      "   macro avg       0.55      0.55      0.54        30\n",
      "weighted avg       0.56      0.57      0.56        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest Performance:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eafb2dfe",
   "metadata": {},
   "source": [
    ">> Accuracy is insufficient for imbalanced data; focus on precision, recall, and F1-score \n",
    ">> Weighted Avg F1-Score-Random Forest outperforms Logistic Regression in balancing precision and recall across both classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54face3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Next Steps:\n",
    "    Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a27f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f462b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#save the model\n",
    "with open(\"logistic_regression_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(lr_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a95a620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scaler\n",
    "with open(\"scaler.pkl\", \"wb\") as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a767b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c97b0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and scaler\n",
    "with open(\"logistic_regression_model.pkl\", \"rb\") as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "with open(\"scaler.pkl\", \"rb\") as scaler_file:\n",
    "    scaler = pickle.load(scaler_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8e67208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted that student will: Pass \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define input data\n",
    "# Features: Attendance_Percentage, Midterm_Score, Study_Hours, Health_Status, School_Type\n",
    "input_data = np.array([[75, 60, 5, \"Healthy\", \"Private\"]])\n",
    "\n",
    "# Encode categorical features\n",
    "# Encode categorical features using np.where\n",
    "input_data[:, 3] = np.where(input_data[:, 3] == \"Healthy\", 0, 1)  # Health_Status\n",
    "input_data[:, 4] = np.where(input_data[:, 4] == \"Government\", 0, 1)  # School_Type\n",
    "\n",
    "# Convert to float for scaling\n",
    "input_data = input_data.astype(float)\n",
    "\n",
    "\n",
    "# Convert to float for scaling\n",
    "input_data = input_data.astype(float)\n",
    "\n",
    "\n",
    "\n",
    "# Split into numerical and categorical features\n",
    "numerical_features = input_data[:, :3]  # First 3 columns: Attendance_Percentage, Midterm_Score, Study_Hours\n",
    "categorical_features = input_data[:, 3:]  # Last 2 columns: Health_Status, School_Type\n",
    "\n",
    "\n",
    "# Apply scaling to numerical features\n",
    "scaled_numerical = scaler.transform(numerical_features)\n",
    "\n",
    "\n",
    "\n",
    "# Combine scaled numerical and categorical features\n",
    "final_input = np.hstack([numerical_features, categorical_features])\n",
    "\n",
    "# Combine scaled numerical and categorical features\n",
    "final_input = np.hstack([numerical_features, categorical_features])\n",
    "# horizontally stacks (combines) two NumPy arrays-adds columns side by side\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(final_input)\n",
    "\n",
    "\n",
    "# Interpret result\n",
    "if prediction[0] == 1:\n",
    "    print(\"Predicted that student will: Pass \")\n",
    "else:\n",
    "    print(\"Predicted that student will: Fail \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6123e7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=[0]>>>>>preciction[0]\n",
    "prediction=[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7df29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4442cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## techniques to improve performance:\n",
    "1.transform/scale data\n",
    "2.treat outliers\n",
    "3.add new features\n",
    "4.use different algorithm\n",
    "5.model hyperparameter tuning\n",
    "6.train on more data\n",
    "7.regularization l1, l2\n",
    "8.cross validation\n",
    "9.use proper feature selection method:\n",
    "    filter, wrapper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
