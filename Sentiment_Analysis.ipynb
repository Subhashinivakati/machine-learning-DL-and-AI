{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301416ad",
   "metadata": {},
   "source": [
    "# step 1: Define Project Goal & Acquire Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6568f93b",
   "metadata": {},
   "source": [
    "To build an accurate machine learning model capable of classifying movie reviews as either 'positive' or 'negative' based on their textual content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4582f9",
   "metadata": {},
   "source": [
    "# Step 2: Data Loading and Initial Exploration (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6812d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import contractions\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7630e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure NLTK data is downloaded (run these once)\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53fa419a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Train.csv')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f47cd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>\"Western Union\" is something of a forgotten cl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>This movie is an incredible piece of work. It ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>My wife and I watched this movie because we pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>When I first watched Flatliners, I was amazed....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>Why would this film be so good, but only gross...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      I grew up (b. 1965) watching and loving the Th...      0\n",
       "1      When I put this movie in my DVD player, and sa...      0\n",
       "2      Why do people who do not know what a particula...      0\n",
       "3      Even though I have great interest in Biblical ...      0\n",
       "4      Im a die hard Dads Army fan and nothing will e...      1\n",
       "...                                                  ...    ...\n",
       "39995  \"Western Union\" is something of a forgotten cl...      1\n",
       "39996  This movie is an incredible piece of work. It ...      1\n",
       "39997  My wife and I watched this movie because we pl...      0\n",
       "39998  When I first watched Flatliners, I was amazed....      1\n",
       "39999  Why would this film be so good, but only gross...      1\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9205ff46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5243c6f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"Thunderbirds\" before school, during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The only high point was the snappy theme tune. Not that it could compare with the original score of the Thunderbirds. Thankfully early Saturday mornings one television channel still plays reruns of the series Gerry Anderson and his wife created. Jonatha Frakes should hand in his directors chair, his version was completely hopeless. A waste of film. Utter rubbish. A CGI remake may be acceptable but replacing marionettes with Homo sapiens subsp. sapiens was a huge error of judgment.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6393515",
   "metadata": {},
   "source": [
    "# Step 3: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a31e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word=\"I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. No, nor, not liked\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550a2a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove spaces\n",
    "def remove_spaces(data):\n",
    "    clean_text = data.replace('\\\\n',' ').replace('\\t',' ').replace('\\\\',' ')\n",
    "    return clean_text\n",
    "\n",
    "# contraction mapping\n",
    "def expand_text(data):\n",
    "    expanded_text = contractions.fix(data)\n",
    "    return expanded_text\n",
    "\n",
    "# handling accented characters\n",
    "def handling_accented(data):\n",
    "    fixed_text = unidecode(data)\n",
    "    return fixed_text\n",
    "\n",
    "# Cleaning\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('nor')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "def clean_data(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    clean_text = [word.lower() for word in tokens if (word not in punctuation) and (word.lower() not in stopword_list) and (len(word)>2) and (word.isalpha())]\n",
    "    return clean_text\n",
    "\n",
    "# autocorrection\n",
    "\n",
    "def autocorrection(data):\n",
    "    spell = Speller(lang='en')\n",
    "    corrected_text = spell(data)\n",
    "    return corrected_text\n",
    "\n",
    "# lemmatization\n",
    "\n",
    "def lemmatization(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    final_data = []\n",
    "    for word in data:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        final_data.append(lemmatized_word)\n",
    "    return ' '.join(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7357c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count vectorizer \n",
    "tfidf           \n",
    ">>>> 'w1 w2 w3 w4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5aea6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data leakage\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.text, data.label,test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84799fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\VISHNU\n",
      "[nltk_data]     KALE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf55dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_train = x_train.apply(remove_spaces) #removing spaces from training data\n",
    "clean_text_test = x_test.apply(remove_spaces) # removing spaces from testing data\n",
    "\n",
    "clean_text_train = clean_text_train.apply(expand_text)\n",
    "clean_text_test = clean_text_test.apply(expand_text)\n",
    "\n",
    "clean_text_train = clean_text_train.apply(handling_accented)\n",
    "clean_text_test = clean_text_test.apply(handling_accented)\n",
    "\n",
    "clean_text_train = clean_text_train.apply(clean_data)\n",
    "clean_text_test = clean_text_test.apply(clean_data)\n",
    "\n",
    "clean_text_train = clean_text_train.apply(lemmatization)\n",
    "clean_text_test = clean_text_test.apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afd71cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26898    fifth grade language art teacher read book stu...\n",
       "27635    low budget brit pop melodrama focus girl want ...\n",
       "3036     well watched movie little year ago pulled dust...\n",
       "5604     would almost give however confusing part well ...\n",
       "36111    full length feature film world bridge found fi...\n",
       "                               ...                        \n",
       "6265     movie one worst movie ever seen life waste tim...\n",
       "11284    movie inspiring anyone tough jam whether finan...\n",
       "38158    east side story documentary musical comedy sta...\n",
       "860      one boot one point doctor assistant refers wor...\n",
       "15795    movie horrible lighting terrible camera moveme...\n",
       "Name: text, Length: 30000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400392b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count vectorizer, Tfidf\n",
    "Parameters\n",
    "\n",
    "max_df >> by default >> 1.0 >> 100% #This means that terms (words) that appear in more than 95% of the documents will be ignored.\n",
    "100 documents >> 0.95 >>95%\n",
    "\n",
    "min_df >> by default >> 1 >> single document # ignores words that are present in only or less documents\n",
    "100 documents >> 1 >> >>15 >>\n",
    "\n",
    "max_features >> 1000 #This means that only the top 1000 most frequent terms will be considered.\n",
    "\n",
    "stopword : 'english'\n",
    "    \n",
    "lower_case : True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5828bb63",
   "metadata": {},
   "source": [
    "# Step 4: Feature Engineering / Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e4b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vectorizer\n",
    "count = CountVectorizer(max_df = 0.95, max_features=1000)\n",
    "count_val_train = count.fit_transform(clean_text_train)\n",
    "count_val_test = count.transform(clean_text_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adc21ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30000x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1617635 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_val_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7c74cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ability', 'able', 'absolutely', 'accent', 'across', 'act',\n",
       "       'acted', 'acting', 'action', 'actor', 'actress', 'actual',\n",
       "       'actually', 'adaptation', 'add', 'admit', 'adult', 'adventure',\n",
       "       'age', 'ago', 'agree', 'air', 'alien', 'alive', 'almost', 'alone',\n",
       "       'along', 'already', 'also', 'although', 'always', 'amazing',\n",
       "       'america', 'american', 'among', 'amount', 'animal', 'animation',\n",
       "       'annoying', 'another', 'answer', 'anyone', 'anything', 'anyway',\n",
       "       'apart', 'apparently', 'appeal', 'appear', 'appearance', 'appears',\n",
       "       'appreciate', 'army', 'around', 'art', 'aside', 'ask', 'aspect',\n",
       "       'atmosphere', 'attack', 'attempt', 'attention', 'audience',\n",
       "       'average', 'avoid', 'award', 'away', 'awesome', 'awful', 'baby',\n",
       "       'back', 'background', 'bad', 'badly', 'band', 'barely', 'based',\n",
       "       'basic', 'basically', 'battle', 'beautiful', 'beauty', 'became',\n",
       "       'become', 'becomes', 'begin', 'beginning', 'behind', 'belief',\n",
       "       'believable', 'believe', 'best', 'better', 'beyond', 'big',\n",
       "       'biggest', 'bill', 'bit', 'bizarre', 'black', 'blood', 'blue',\n",
       "       'body', 'book', 'bored', 'boring', 'bother', 'box', 'boy', 'brain',\n",
       "       'break', 'brilliant', 'bring', 'brings', 'british', 'brother',\n",
       "       'brought', 'budget', 'bunch', 'business', 'buy', 'call', 'called',\n",
       "       'came', 'camera', 'camp', 'car', 'care', 'career', 'carry',\n",
       "       'cartoon', 'case', 'cast', 'casting', 'cat', 'catch', 'caught',\n",
       "       'century', 'certain', 'certainly', 'chance', 'change', 'changed',\n",
       "       'channel', 'character', 'chase', 'cheap', 'check', 'cheesy',\n",
       "       'child', 'choice', 'christmas', 'cinema', 'cinematography', 'city',\n",
       "       'class', 'classic', 'clear', 'clearly', 'clever', 'cliche',\n",
       "       'close', 'college', 'color', 'come', 'comedy', 'comic', 'coming',\n",
       "       'comment', 'common', 'company', 'compared', 'complete',\n",
       "       'completely', 'computer', 'concept', 'conclusion', 'consider',\n",
       "       'considering', 'control', 'convincing', 'cool', 'cop', 'copy',\n",
       "       'costume', 'could', 'country', 'couple', 'course', 'cover', 'crap',\n",
       "       'crazy', 'create', 'created', 'creature', 'credit', 'creepy',\n",
       "       'crew', 'crime', 'critic', 'cry', 'culture', 'cut', 'cute',\n",
       "       'dance', 'dancing', 'dark', 'date', 'daughter', 'david', 'day',\n",
       "       'dead', 'deal', 'death', 'decent', 'decide', 'decided', 'decides',\n",
       "       'deep', 'definitely', 'depth', 'deserves', 'despite', 'detail',\n",
       "       'development', 'dialog', 'dialogue', 'die', 'died', 'different',\n",
       "       'difficult', 'directed', 'directing', 'direction', 'director',\n",
       "       'disappointed', 'disney', 'doctor', 'documentary', 'dog', 'done',\n",
       "       'door', 'doubt', 'drama', 'dramatic', 'dream', 'drive', 'drug',\n",
       "       'due', 'dull', 'dumb', 'dvd', 'earlier', 'early', 'earth',\n",
       "       'easily', 'easy', 'editing', 'effect', 'effort', 'either',\n",
       "       'element', 'else', 'emotion', 'emotional', 'end', 'ended',\n",
       "       'ending', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'enough',\n",
       "       'entertaining', 'entertainment', 'entire', 'entirely', 'episode',\n",
       "       'era', 'escape', 'especially', 'etc', 'even', 'event',\n",
       "       'eventually', 'ever', 'every', 'everyone', 'everything', 'evil',\n",
       "       'exactly', 'example', 'excellent', 'except', 'exciting', 'expect',\n",
       "       'expected', 'expecting', 'experience', 'extra', 'extremely', 'eye',\n",
       "       'face', 'fact', 'fails', 'fairly', 'fall', 'familiar', 'family',\n",
       "       'famous', 'fan', 'fantastic', 'fantasy', 'far', 'fast', 'father',\n",
       "       'favorite', 'fear', 'feature', 'feel', 'feeling', 'felt', 'female',\n",
       "       'fight', 'fighting', 'figure', 'filled', 'film', 'filmed',\n",
       "       'filmmaker', 'final', 'finally', 'find', 'fine', 'fire', 'first',\n",
       "       'fit', 'five', 'flat', 'flaw', 'flick', 'focus', 'follow',\n",
       "       'following', 'follows', 'footage', 'force', 'forced', 'forget',\n",
       "       'form', 'former', 'forward', 'found', 'four', 'free', 'french',\n",
       "       'friend', 'front', 'full', 'fun', 'funny', 'future', 'game',\n",
       "       'gang', 'gave', 'gay', 'general', 'genius', 'genre', 'george',\n",
       "       'german', 'get', 'getting', 'ghost', 'girl', 'girlfriend', 'give',\n",
       "       'given', 'giving', 'go', 'god', 'going', 'gone', 'good', 'gore',\n",
       "       'got', 'great', 'greatest', 'group', 'guess', 'gun', 'guy', 'hair',\n",
       "       'half', 'hand', 'happen', 'happened', 'happens', 'happy', 'hard',\n",
       "       'hardly', 'hate', 'head', 'hear', 'heard', 'heart', 'hell', 'help',\n",
       "       'hero', 'high', 'highly', 'hilarious', 'history', 'hit', 'hold',\n",
       "       'hole', 'hollywood', 'home', 'honest', 'hope', 'horrible',\n",
       "       'horror', 'hot', 'hour', 'house', 'however', 'huge', 'human',\n",
       "       'humor', 'humour', 'hurt', 'husband', 'idea', 'image', 'imagine',\n",
       "       'imdb', 'important', 'impressive', 'including', 'incredible',\n",
       "       'incredibly', 'indeed', 'indian', 'inside', 'instead',\n",
       "       'intelligent', 'interest', 'interested', 'interesting', 'involved',\n",
       "       'involving', 'island', 'issue', 'italian', 'jack', 'james', 'jane',\n",
       "       'japanese', 'job', 'joe', 'john', 'joke', 'keep', 'kept', 'kid',\n",
       "       'kill', 'killed', 'killer', 'killing', 'kind', 'king', 'knew',\n",
       "       'know', 'known', 'lack', 'lady', 'lame', 'land', 'language',\n",
       "       'large', 'last', 'late', 'later', 'laugh', 'laughing', 'law',\n",
       "       'lead', 'leading', 'leaf', 'learn', 'least', 'leave', 'lee',\n",
       "       'left', 'less', 'let', 'level', 'lie', 'life', 'light', 'like',\n",
       "       'liked', 'line', 'list', 'little', 'live', 'living', 'local',\n",
       "       'location', 'long', 'longer', 'look', 'looked', 'looking', 'lost',\n",
       "       'lot', 'love', 'loved', 'lover', 'low', 'mad', 'made', 'main',\n",
       "       'major', 'make', 'maker', 'making', 'male', 'man', 'manages',\n",
       "       'many', 'mark', 'married', 'master', 'masterpiece', 'match',\n",
       "       'material', 'matter', 'may', 'maybe', 'mean', 'meaning', 'meant',\n",
       "       'meet', 'member', 'memorable', 'memory', 'men', 'mention',\n",
       "       'mentioned', 'mess', 'message', 'michael', 'middle', 'might',\n",
       "       'million', 'mind', 'minute', 'miss', 'missed', 'missing',\n",
       "       'mistake', 'modern', 'moment', 'money', 'monster', 'mostly',\n",
       "       'mother', 'move', 'movie', 'moving', 'much', 'murder', 'music',\n",
       "       'musical', 'must', 'mystery', 'name', 'named', 'nature', 'near',\n",
       "       'nearly', 'need', 'needed', 'neither', 'never', 'new', 'next',\n",
       "       'nice', 'night', 'none', 'nor', 'not', 'note', 'nothing', 'novel',\n",
       "       'nudity', 'number', 'obvious', 'obviously', 'odd', 'offer',\n",
       "       'office', 'often', 'okay', 'old', 'older', 'one', 'open',\n",
       "       'opening', 'opinion', 'opportunity', 'order', 'original', 'oscar',\n",
       "       'others', 'otherwise', 'outside', 'overall', 'pace', 'parent',\n",
       "       'park', 'part', 'particular', 'particularly', 'party', 'past',\n",
       "       'pathetic', 'paul', 'pay', 'people', 'perfect', 'perfectly',\n",
       "       'performance', 'perhaps', 'period', 'person', 'personal', 'peter',\n",
       "       'pick', 'picture', 'piece', 'place', 'plain', 'plan', 'play',\n",
       "       'played', 'player', 'playing', 'please', 'plenty', 'plot', 'plus',\n",
       "       'point', 'pointless', 'police', 'political', 'poor', 'poorly',\n",
       "       'popular', 'portrayal', 'portrayed', 'positive', 'possible',\n",
       "       'possibly', 'potential', 'power', 'powerful', 'predictable',\n",
       "       'premise', 'present', 'pretty', 'previous', 'prison', 'probably',\n",
       "       'problem', 'produced', 'producer', 'production', 'project',\n",
       "       'public', 'pull', 'pure', 'purpose', 'put', 'quality', 'question',\n",
       "       'quickly', 'quite', 'rate', 'rather', 'rating', 'read', 'reading',\n",
       "       'real', 'realistic', 'reality', 'realize', 'really', 'reason',\n",
       "       'recent', 'recently', 'recommend', 'recommended', 'red',\n",
       "       'relationship', 'release', 'released', 'remake', 'remember',\n",
       "       'rent', 'respect', 'rest', 'result', 'return', 'revenge', 'review',\n",
       "       'reviewer', 'rich', 'richard', 'ride', 'ridiculous', 'right',\n",
       "       'ring', 'road', 'robert', 'rock', 'role', 'romance', 'romantic',\n",
       "       'room', 'run', 'running', 'sad', 'sadly', 'said', 'save', 'saw',\n",
       "       'say', 'saying', 'scary', 'scene', 'school', 'science',\n",
       "       'scientist', 'score', 'scott', 'screen', 'screenplay', 'script',\n",
       "       'season', 'second', 'secret', 'see', 'seeing', 'seem', 'seemed',\n",
       "       'seems', 'seen', 'sense', 'sequel', 'sequence', 'series',\n",
       "       'serious', 'seriously', 'set', 'setting', 'several', 'sex',\n",
       "       'sexual', 'shame', 'ship', 'shoot', 'shooting', 'short', 'shot',\n",
       "       'show', 'showing', 'shown', 'sick', 'side', 'silly', 'similar',\n",
       "       'simple', 'simply', 'since', 'singing', 'single', 'sister', 'sit',\n",
       "       'situation', 'slightly', 'slow', 'small', 'society', 'soldier',\n",
       "       'solid', 'somehow', 'someone', 'something', 'sometimes',\n",
       "       'somewhat', 'son', 'song', 'soon', 'sorry', 'sort', 'soul',\n",
       "       'sound', 'soundtrack', 'space', 'speak', 'special', 'spend',\n",
       "       'spent', 'spirit', 'spoiler', 'spot', 'stage', 'stand', 'standard',\n",
       "       'star', 'start', 'started', 'state', 'stay', 'stick', 'still',\n",
       "       'stop', 'store', 'story', 'storyline', 'straight', 'strange',\n",
       "       'street', 'strong', 'student', 'studio', 'stuff', 'stupid',\n",
       "       'style', 'subject', 'success', 'successful', 'suck', 'suddenly',\n",
       "       'superb', 'supporting', 'supposed', 'sure', 'surprise',\n",
       "       'surprised', 'suspense', 'sweet', 'take', 'taken', 'taking',\n",
       "       'tale', 'talent', 'talented', 'talk', 'talking', 'taste', 'team',\n",
       "       'teen', 'teenager', 'television', 'tell', 'telling', 'ten',\n",
       "       'tension', 'term', 'terrible', 'thanks', 'theater', 'theme',\n",
       "       'thing', 'think', 'thinking', 'third', 'though', 'thought',\n",
       "       'three', 'thriller', 'throughout', 'throw', 'time', 'title',\n",
       "       'today', 'together', 'told', 'tom', 'tone', 'took', 'top', 'total',\n",
       "       'totally', 'touch', 'towards', 'town', 'track', 'trailer', 'train',\n",
       "       'tried', 'trouble', 'true', 'truly', 'truth', 'try', 'trying',\n",
       "       'turn', 'turned', 'twist', 'two', 'type', 'typical', 'ultimately',\n",
       "       'understand', 'unfortunately', 'unique', 'unless', 'unlike',\n",
       "       'upon', 'us', 'use', 'used', 'using', 'usual', 'usually', 'value',\n",
       "       'vampire', 'van', 'various', 'version', 'victim', 'video', 'view',\n",
       "       'viewer', 'viewing', 'villain', 'violence', 'violent', 'visual',\n",
       "       'voice', 'wait', 'waiting', 'walk', 'want', 'wanted', 'war',\n",
       "       'waste', 'wasted', 'watch', 'watched', 'watching', 'water', 'way',\n",
       "       'weak', 'week', 'weird', 'well', 'went', 'western', 'whatever',\n",
       "       'whether', 'white', 'whole', 'whose', 'wife', 'william', 'win',\n",
       "       'wish', 'within', 'without', 'woman', 'wonder', 'wonderful',\n",
       "       'wood', 'word', 'work', 'worked', 'working', 'world', 'worse',\n",
       "       'worst', 'worth', 'would', 'write', 'writer', 'writing', 'written',\n",
       "       'wrong', 'wrote', 'yeah', 'year', 'yes', 'yet', 'york', 'young',\n",
       "       'younger', 'zombie'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4991f5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accent</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>acted</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>zombie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ability  able  absolutely  accent  across  act  acted  acting  action  \\\n",
       "0            0     0           0       0       0    0      0       2       0   \n",
       "1            0     0           0       0       0    0      0       0       0   \n",
       "2            0     0           0       0       0    0      0       0       0   \n",
       "3            0     0           0       1       0    0      0       0       0   \n",
       "4            0     0           2       0       0    0      0       0       0   \n",
       "...        ...   ...         ...     ...     ...  ...    ...     ...     ...   \n",
       "29995        0     0           0       0       0    1      0       1       0   \n",
       "29996        0     0           0       0       0    0      0       0       0   \n",
       "29997        0     0           0       0       0    0      0       0       0   \n",
       "29998        0     0           0       0       0    0      0       1       0   \n",
       "29999        0     0           0       0       0    0      0       1       0   \n",
       "\n",
       "       actor  ...  wrong  wrote  yeah  year  yes  yet  york  young  younger  \\\n",
       "0          0  ...      0      0     0     0    0    0     0      0        0   \n",
       "1          0  ...      0      0     0     0    0    0     0      0        0   \n",
       "2          0  ...      0      0     0     1    0    0     0      0        0   \n",
       "3          0  ...      0      0     0     0    0    0     0      0        0   \n",
       "4          0  ...      0      0     0     0    0    0     0      0        0   \n",
       "...      ...  ...    ...    ...   ...   ...  ...  ...   ...    ...      ...   \n",
       "29995      0  ...      0      0     0     0    0    0     0      0        0   \n",
       "29996      0  ...      0      0     0     0    0    0     0      0        0   \n",
       "29997      0  ...      0      0     0     1    0    0     0      0        0   \n",
       "29998      0  ...      1      0     0     0    0    0     0      0        0   \n",
       "29999      0  ...      0      1     0     1    0    0     0      0        0   \n",
       "\n",
       "       zombie  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "29995       0  \n",
       "29996       0  \n",
       "29997       0  \n",
       "29998       0  \n",
       "29999       0  \n",
       "\n",
       "[30000 rows x 1000 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(count_val_train.A,columns = count.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0825052d",
   "metadata": {},
   "source": [
    "# Step 5: Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4344c3f",
   "metadata": {},
   "source": [
    "# Step 6: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbff3a9",
   "metadata": {},
   "source": [
    "# Step 7: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f2ec33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.06"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model\n",
    "count_mnb = MultinomialNB()\n",
    "count_mnb.fit(count_val_train.A,y_train)\n",
    "predict_count = count_mnb.predict(count_val_test.A)\n",
    "accuracy_count = accuracy_score(y_test,predict_count)*100\n",
    "accuracy_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dcdad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_df = 0.95, max_features=1000)\n",
    "tfidf_train = tfidf.fit_transform(clean_text_train)\n",
    "tfidf_test = tfidf.transform(clean_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d59f87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30000x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1617635 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65a013d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b3fbfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6f24e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ability', 'able', 'absolutely', 'accent', 'across', 'act',\n",
       "       'acted', 'acting', 'action', 'actor', 'actress', 'actual',\n",
       "       'actually', 'adaptation', 'add', 'admit', 'adult', 'adventure',\n",
       "       'age', 'ago', 'agree', 'air', 'alien', 'alive', 'almost', 'alone',\n",
       "       'along', 'already', 'also', 'although', 'always', 'amazing',\n",
       "       'america', 'american', 'among', 'amount', 'animal', 'animation',\n",
       "       'annoying', 'another', 'answer', 'anyone', 'anything', 'anyway',\n",
       "       'apart', 'apparently', 'appeal', 'appear', 'appearance', 'appears',\n",
       "       'appreciate', 'army', 'around', 'art', 'aside', 'ask', 'aspect',\n",
       "       'atmosphere', 'attack', 'attempt', 'attention', 'audience',\n",
       "       'average', 'avoid', 'award', 'away', 'awesome', 'awful', 'baby',\n",
       "       'back', 'background', 'bad', 'badly', 'band', 'barely', 'based',\n",
       "       'basic', 'basically', 'battle', 'beautiful', 'beauty', 'became',\n",
       "       'become', 'becomes', 'begin', 'beginning', 'behind', 'belief',\n",
       "       'believable', 'believe', 'best', 'better', 'beyond', 'big',\n",
       "       'biggest', 'bill', 'bit', 'bizarre', 'black', 'blood', 'blue',\n",
       "       'body', 'book', 'bored', 'boring', 'bother', 'box', 'boy', 'brain',\n",
       "       'break', 'brilliant', 'bring', 'brings', 'british', 'brother',\n",
       "       'brought', 'budget', 'bunch', 'business', 'buy', 'call', 'called',\n",
       "       'came', 'camera', 'camp', 'car', 'care', 'career', 'carry',\n",
       "       'cartoon', 'case', 'cast', 'casting', 'cat', 'catch', 'caught',\n",
       "       'century', 'certain', 'certainly', 'chance', 'change', 'changed',\n",
       "       'channel', 'character', 'chase', 'cheap', 'check', 'cheesy',\n",
       "       'child', 'choice', 'christmas', 'cinema', 'cinematography', 'city',\n",
       "       'class', 'classic', 'clear', 'clearly', 'clever', 'cliche',\n",
       "       'close', 'college', 'color', 'come', 'comedy', 'comic', 'coming',\n",
       "       'comment', 'common', 'company', 'compared', 'complete',\n",
       "       'completely', 'computer', 'concept', 'conclusion', 'consider',\n",
       "       'considering', 'control', 'convincing', 'cool', 'cop', 'copy',\n",
       "       'costume', 'could', 'country', 'couple', 'course', 'cover', 'crap',\n",
       "       'crazy', 'create', 'created', 'creature', 'credit', 'creepy',\n",
       "       'crew', 'crime', 'critic', 'cry', 'culture', 'cut', 'cute',\n",
       "       'dance', 'dancing', 'dark', 'date', 'daughter', 'david', 'day',\n",
       "       'dead', 'deal', 'death', 'decent', 'decide', 'decided', 'decides',\n",
       "       'deep', 'definitely', 'depth', 'deserves', 'despite', 'detail',\n",
       "       'development', 'dialog', 'dialogue', 'die', 'died', 'different',\n",
       "       'difficult', 'directed', 'directing', 'direction', 'director',\n",
       "       'disappointed', 'disney', 'doctor', 'documentary', 'dog', 'done',\n",
       "       'door', 'doubt', 'drama', 'dramatic', 'dream', 'drive', 'drug',\n",
       "       'due', 'dull', 'dumb', 'dvd', 'earlier', 'early', 'earth',\n",
       "       'easily', 'easy', 'editing', 'effect', 'effort', 'either',\n",
       "       'element', 'else', 'emotion', 'emotional', 'end', 'ended',\n",
       "       'ending', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'enough',\n",
       "       'entertaining', 'entertainment', 'entire', 'entirely', 'episode',\n",
       "       'era', 'escape', 'especially', 'etc', 'even', 'event',\n",
       "       'eventually', 'ever', 'every', 'everyone', 'everything', 'evil',\n",
       "       'exactly', 'example', 'excellent', 'except', 'exciting', 'expect',\n",
       "       'expected', 'expecting', 'experience', 'extra', 'extremely', 'eye',\n",
       "       'face', 'fact', 'fails', 'fairly', 'fall', 'familiar', 'family',\n",
       "       'famous', 'fan', 'fantastic', 'fantasy', 'far', 'fast', 'father',\n",
       "       'favorite', 'fear', 'feature', 'feel', 'feeling', 'felt', 'female',\n",
       "       'fight', 'fighting', 'figure', 'filled', 'film', 'filmed',\n",
       "       'filmmaker', 'final', 'finally', 'find', 'fine', 'fire', 'first',\n",
       "       'fit', 'five', 'flat', 'flaw', 'flick', 'focus', 'follow',\n",
       "       'following', 'follows', 'footage', 'force', 'forced', 'forget',\n",
       "       'form', 'former', 'forward', 'found', 'four', 'free', 'french',\n",
       "       'friend', 'front', 'full', 'fun', 'funny', 'future', 'game',\n",
       "       'gang', 'gave', 'gay', 'general', 'genius', 'genre', 'george',\n",
       "       'german', 'get', 'getting', 'ghost', 'girl', 'girlfriend', 'give',\n",
       "       'given', 'giving', 'go', 'god', 'going', 'gone', 'good', 'gore',\n",
       "       'got', 'great', 'greatest', 'group', 'guess', 'gun', 'guy', 'hair',\n",
       "       'half', 'hand', 'happen', 'happened', 'happens', 'happy', 'hard',\n",
       "       'hardly', 'hate', 'head', 'hear', 'heard', 'heart', 'hell', 'help',\n",
       "       'hero', 'high', 'highly', 'hilarious', 'history', 'hit', 'hold',\n",
       "       'hole', 'hollywood', 'home', 'honest', 'hope', 'horrible',\n",
       "       'horror', 'hot', 'hour', 'house', 'however', 'huge', 'human',\n",
       "       'humor', 'humour', 'hurt', 'husband', 'idea', 'image', 'imagine',\n",
       "       'imdb', 'important', 'impressive', 'including', 'incredible',\n",
       "       'incredibly', 'indeed', 'indian', 'inside', 'instead',\n",
       "       'intelligent', 'interest', 'interested', 'interesting', 'involved',\n",
       "       'involving', 'island', 'issue', 'italian', 'jack', 'james', 'jane',\n",
       "       'japanese', 'job', 'joe', 'john', 'joke', 'keep', 'kept', 'kid',\n",
       "       'kill', 'killed', 'killer', 'killing', 'kind', 'king', 'knew',\n",
       "       'know', 'known', 'lack', 'lady', 'lame', 'land', 'language',\n",
       "       'large', 'last', 'late', 'later', 'laugh', 'laughing', 'law',\n",
       "       'lead', 'leading', 'leaf', 'learn', 'least', 'leave', 'lee',\n",
       "       'left', 'less', 'let', 'level', 'lie', 'life', 'light', 'like',\n",
       "       'liked', 'line', 'list', 'little', 'live', 'living', 'local',\n",
       "       'location', 'long', 'longer', 'look', 'looked', 'looking', 'lost',\n",
       "       'lot', 'love', 'loved', 'lover', 'low', 'mad', 'made', 'main',\n",
       "       'major', 'make', 'maker', 'making', 'male', 'man', 'manages',\n",
       "       'many', 'mark', 'married', 'master', 'masterpiece', 'match',\n",
       "       'material', 'matter', 'may', 'maybe', 'mean', 'meaning', 'meant',\n",
       "       'meet', 'member', 'memorable', 'memory', 'men', 'mention',\n",
       "       'mentioned', 'mess', 'message', 'michael', 'middle', 'might',\n",
       "       'million', 'mind', 'minute', 'miss', 'missed', 'missing',\n",
       "       'mistake', 'modern', 'moment', 'money', 'monster', 'mostly',\n",
       "       'mother', 'move', 'movie', 'moving', 'much', 'murder', 'music',\n",
       "       'musical', 'must', 'mystery', 'name', 'named', 'nature', 'near',\n",
       "       'nearly', 'need', 'needed', 'neither', 'never', 'new', 'next',\n",
       "       'nice', 'night', 'none', 'nor', 'not', 'note', 'nothing', 'novel',\n",
       "       'nudity', 'number', 'obvious', 'obviously', 'odd', 'offer',\n",
       "       'office', 'often', 'okay', 'old', 'older', 'one', 'open',\n",
       "       'opening', 'opinion', 'opportunity', 'order', 'original', 'oscar',\n",
       "       'others', 'otherwise', 'outside', 'overall', 'pace', 'parent',\n",
       "       'park', 'part', 'particular', 'particularly', 'party', 'past',\n",
       "       'pathetic', 'paul', 'pay', 'people', 'perfect', 'perfectly',\n",
       "       'performance', 'perhaps', 'period', 'person', 'personal', 'peter',\n",
       "       'pick', 'picture', 'piece', 'place', 'plain', 'plan', 'play',\n",
       "       'played', 'player', 'playing', 'please', 'plenty', 'plot', 'plus',\n",
       "       'point', 'pointless', 'police', 'political', 'poor', 'poorly',\n",
       "       'popular', 'portrayal', 'portrayed', 'positive', 'possible',\n",
       "       'possibly', 'potential', 'power', 'powerful', 'predictable',\n",
       "       'premise', 'present', 'pretty', 'previous', 'prison', 'probably',\n",
       "       'problem', 'produced', 'producer', 'production', 'project',\n",
       "       'public', 'pull', 'pure', 'purpose', 'put', 'quality', 'question',\n",
       "       'quickly', 'quite', 'rate', 'rather', 'rating', 'read', 'reading',\n",
       "       'real', 'realistic', 'reality', 'realize', 'really', 'reason',\n",
       "       'recent', 'recently', 'recommend', 'recommended', 'red',\n",
       "       'relationship', 'release', 'released', 'remake', 'remember',\n",
       "       'rent', 'respect', 'rest', 'result', 'return', 'revenge', 'review',\n",
       "       'reviewer', 'rich', 'richard', 'ride', 'ridiculous', 'right',\n",
       "       'ring', 'road', 'robert', 'rock', 'role', 'romance', 'romantic',\n",
       "       'room', 'run', 'running', 'sad', 'sadly', 'said', 'save', 'saw',\n",
       "       'say', 'saying', 'scary', 'scene', 'school', 'science',\n",
       "       'scientist', 'score', 'scott', 'screen', 'screenplay', 'script',\n",
       "       'season', 'second', 'secret', 'see', 'seeing', 'seem', 'seemed',\n",
       "       'seems', 'seen', 'sense', 'sequel', 'sequence', 'series',\n",
       "       'serious', 'seriously', 'set', 'setting', 'several', 'sex',\n",
       "       'sexual', 'shame', 'ship', 'shoot', 'shooting', 'short', 'shot',\n",
       "       'show', 'showing', 'shown', 'sick', 'side', 'silly', 'similar',\n",
       "       'simple', 'simply', 'since', 'singing', 'single', 'sister', 'sit',\n",
       "       'situation', 'slightly', 'slow', 'small', 'society', 'soldier',\n",
       "       'solid', 'somehow', 'someone', 'something', 'sometimes',\n",
       "       'somewhat', 'son', 'song', 'soon', 'sorry', 'sort', 'soul',\n",
       "       'sound', 'soundtrack', 'space', 'speak', 'special', 'spend',\n",
       "       'spent', 'spirit', 'spoiler', 'spot', 'stage', 'stand', 'standard',\n",
       "       'star', 'start', 'started', 'state', 'stay', 'stick', 'still',\n",
       "       'stop', 'store', 'story', 'storyline', 'straight', 'strange',\n",
       "       'street', 'strong', 'student', 'studio', 'stuff', 'stupid',\n",
       "       'style', 'subject', 'success', 'successful', 'suck', 'suddenly',\n",
       "       'superb', 'supporting', 'supposed', 'sure', 'surprise',\n",
       "       'surprised', 'suspense', 'sweet', 'take', 'taken', 'taking',\n",
       "       'tale', 'talent', 'talented', 'talk', 'talking', 'taste', 'team',\n",
       "       'teen', 'teenager', 'television', 'tell', 'telling', 'ten',\n",
       "       'tension', 'term', 'terrible', 'thanks', 'theater', 'theme',\n",
       "       'thing', 'think', 'thinking', 'third', 'though', 'thought',\n",
       "       'three', 'thriller', 'throughout', 'throw', 'time', 'title',\n",
       "       'today', 'together', 'told', 'tom', 'tone', 'took', 'top', 'total',\n",
       "       'totally', 'touch', 'towards', 'town', 'track', 'trailer', 'train',\n",
       "       'tried', 'trouble', 'true', 'truly', 'truth', 'try', 'trying',\n",
       "       'turn', 'turned', 'twist', 'two', 'type', 'typical', 'ultimately',\n",
       "       'understand', 'unfortunately', 'unique', 'unless', 'unlike',\n",
       "       'upon', 'us', 'use', 'used', 'using', 'usual', 'usually', 'value',\n",
       "       'vampire', 'van', 'various', 'version', 'victim', 'video', 'view',\n",
       "       'viewer', 'viewing', 'villain', 'violence', 'violent', 'visual',\n",
       "       'voice', 'wait', 'waiting', 'walk', 'want', 'wanted', 'war',\n",
       "       'waste', 'wasted', 'watch', 'watched', 'watching', 'water', 'way',\n",
       "       'weak', 'week', 'weird', 'well', 'went', 'western', 'whatever',\n",
       "       'whether', 'white', 'whole', 'whose', 'wife', 'william', 'win',\n",
       "       'wish', 'within', 'without', 'woman', 'wonder', 'wonderful',\n",
       "       'wood', 'word', 'work', 'worked', 'working', 'world', 'worse',\n",
       "       'worst', 'worth', 'would', 'write', 'writer', 'writing', 'written',\n",
       "       'wrong', 'wrote', 'yeah', 'year', 'yes', 'yet', 'york', 'young',\n",
       "       'younger', 'zombie'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dc56293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accent</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>acted</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>zombie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.189091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ability  able  absolutely    accent  across       act  acted    acting  \\\n",
       "0          0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.182468   \n",
       "1          0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "2          0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "3          0.0   0.0    0.000000  0.137926     0.0  0.000000    0.0  0.000000   \n",
       "4          0.0   0.0    0.321531  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "...        ...   ...         ...       ...     ...       ...    ...       ...   \n",
       "29995      0.0   0.0    0.000000  0.000000     0.0  0.135608    0.0  0.088057   \n",
       "29996      0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "29997      0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "29998      0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.050570   \n",
       "29999      0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.097604   \n",
       "\n",
       "       action  actor  ...    wrong     wrote  yeah      year  yes  yet  york  \\\n",
       "0         0.0    0.0  ...  0.00000  0.000000   0.0  0.000000  0.0  0.0   0.0   \n",
       "1         0.0    0.0  ...  0.00000  0.000000   0.0  0.000000  0.0  0.0   0.0   \n",
       "2         0.0    0.0  ...  0.00000  0.000000   0.0  0.055835  0.0  0.0   0.0   \n",
       "3         0.0    0.0  ...  0.00000  0.000000   0.0  0.000000  0.0  0.0   0.0   \n",
       "4         0.0    0.0  ...  0.00000  0.000000   0.0  0.000000  0.0  0.0   0.0   \n",
       "...       ...    ...  ...      ...       ...   ...       ...  ...  ...   ...   \n",
       "29995     0.0    0.0  ...  0.00000  0.000000   0.0  0.000000  0.0  0.0   0.0   \n",
       "29996     0.0    0.0  ...  0.00000  0.000000   0.0  0.000000  0.0  0.0   0.0   \n",
       "29997     0.0    0.0  ...  0.00000  0.000000   0.0  0.074135  0.0  0.0   0.0   \n",
       "29998     0.0    0.0  ...  0.07508  0.000000   0.0  0.000000  0.0  0.0   0.0   \n",
       "29999     0.0    0.0  ...  0.00000  0.189091   0.0  0.102630  0.0  0.0   0.0   \n",
       "\n",
       "       young  younger  zombie  \n",
       "0        0.0      0.0     0.0  \n",
       "1        0.0      0.0     0.0  \n",
       "2        0.0      0.0     0.0  \n",
       "3        0.0      0.0     0.0  \n",
       "4        0.0      0.0     0.0  \n",
       "...      ...      ...     ...  \n",
       "29995    0.0      0.0     0.0  \n",
       "29996    0.0      0.0     0.0  \n",
       "29997    0.0      0.0     0.0  \n",
       "29998    0.0      0.0     0.0  \n",
       "29999    0.0      0.0     0.0  \n",
       "\n",
       "[30000 rows x 1000 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_train.A, columns = tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef812425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.71"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model\n",
    "tfidf_mnb = MultinomialNB()\n",
    "tfidf_mnb.fit(tfidf_train.A,y_train)\n",
    "predict_tfidf = tfidf_mnb.predict(tfidf_test.A)\n",
    "accuracy_tfidf = accuracy_score(y_test, predict_tfidf)*100\n",
    "accuracy_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd00146",
   "metadata": {},
   "outputs": [],
   "source": [
    "strin=\"we are learning NLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f537cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams\n",
    "from nltk.util import ngrams\n",
    "# [w1,w2,w3]\n",
    "def splitting_dataframe(data):\n",
    "    tokens = data.split()\n",
    "    return tokens\n",
    "\n",
    "data = clean_text_test.apply(splitting_dataframe)\n",
    "def ngram_list(data,ngram_range):\n",
    "    ngram = ngrams(data,ngram_range) # zip file\n",
    "    ngram_list1 = []\n",
    "    for ngram1 in ngram: # opening the zip file\n",
    "        ngram_list1.append(' '.join(ngram1))\n",
    "    return ngram_list1\n",
    "\n",
    "unigrams = data.apply(lambda x : ngram_list(x,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d409f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range >> 1 >> unigrams\n",
    "            >> 2 >> bigrams\n",
    "            >> 3 >> trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b961c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32823    [central, theme, movie, seems, confusion, rela...\n",
       "16298    [excellent, example, cowboy, noir, called, une...\n",
       "28505    [ending, made, heart, jump, throat, proceeded,...\n",
       "6689     [chosen, one, appreciate, quality, story, char...\n",
       "26893    [really, funny, film, especially, second, thir...\n",
       "                               ...                        \n",
       "29415    [film, came, gift, offering, blue, unlike, rev...\n",
       "11359    [first, started, watching, movie, looking, kin...\n",
       "575      [big, mark, music, neil, young, glowing, prais...\n",
       "17398    [watching, lady, ermine, wondering, betty, gra...\n",
       "4189     [crappy, miserably, acted, movie, based, subli...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a17c43bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32823    [central theme, theme movie, movie seems, seem...\n",
       "16298    [excellent example, example cowboy, cowboy noi...\n",
       "28505    [ending made, made heart, heart jump, jump thr...\n",
       "6689     [chosen one, one appreciate, appreciate qualit...\n",
       "26893    [really funny, funny film, film especially, es...\n",
       "                               ...                        \n",
       "29415    [film came, came gift, gift offering, offering...\n",
       "11359    [first started, started watching, watching mov...\n",
       "575      [big mark, mark music, music neil, neil young,...\n",
       "17398    [watching lady, lady ermine, ermine wondering,...\n",
       "4189     [crappy miserably, miserably acted, acted movi...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = data.apply(lambda x : ngram_list(x,2))\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3db03dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32823    [central theme movie, theme movie seems, movie...\n",
       "16298    [excellent example cowboy, example cowboy noir...\n",
       "28505    [ending made heart, made heart jump, heart jum...\n",
       "6689     [chosen one appreciate, one appreciate quality...\n",
       "26893    [really funny film, funny film especially, fil...\n",
       "                               ...                        \n",
       "29415    [film came gift, came gift offering, gift offe...\n",
       "11359    [first started watching, started watching movi...\n",
       "575      [big mark music, mark music neil, music neil y...\n",
       "17398    [watching lady ermine, lady ermine wondering, ...\n",
       "4189     [crappy miserably acted, miserably acted movie...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = data.apply(lambda x : ngram_list(x,3))\n",
    "trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aad28f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32823    [central theme movie seems confusion relations...\n",
       "16298    [excellent example cowboy noir called unemploy...\n",
       "28505    [ending made heart jump throat proceeded leave...\n",
       "6689     [chosen one appreciate quality story character...\n",
       "26893    [really funny film especially second third fou...\n",
       "                               ...                        \n",
       "29415    [film came gift offering blue unlike reviewer,...\n",
       "11359    [first started watching movie looking kind sub...\n",
       "575      [big mark music neil young glowing praise, mar...\n",
       "17398    [watching lady ermine wondering betty grable p...\n",
       "4189     [crappy miserably acted movie based sublimated...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = data.apply(lambda x : ngram_list(x,7)) #7-grams\n",
    "trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708174e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
