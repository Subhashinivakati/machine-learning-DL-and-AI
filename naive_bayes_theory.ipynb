{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96afa099",
   "metadata": {},
   "source": [
    "# naive bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4aca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detectin email is spam or not-\n",
    "\n",
    "offer freee discount >>> spam/not spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827dbb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "column1 column2 column3 output\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de15e4b0",
   "metadata": {},
   "source": [
    ">> naive bayes is supervised classification algorithm based Bayes theorem. This means it calculates the probability of an event happening based on other events that have already happened. It's built upon a powerful idea from mathematics called Bayes' Theorem.\n",
    "\n",
    ">> Why is it called \"Naive\"?\n",
    "The \"Naive\" part is very important! It's called \"Naive\" because it makes assumption: it assumes that all the \"features\" (or characteristics) that describe something are independent of each other.\n",
    "\n",
    "\n",
    "\n",
    ">> what is bayes?\n",
    "It is based on powerful Bayes theorom to find the probability of a event when other event has already happened.\n",
    "\n",
    "\n",
    ">> we require large high dimensional data.\n",
    ">> simple and most effective classification algorthm that make quick prediction.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d25d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 1.1 1.3 1.4 2 2.4\n",
    "10 11 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88864e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants of naive bayes:\n",
    "\n",
    "1. Gausian naive bayes:\n",
    "    It need continues data. whenerever thers is normal distribution and ther is zero skew.\n",
    "\n",
    "2. Multinomial naive bayes:\n",
    "    we use this in NLP. whenever we have discrete data. TF-IDF, bag of words, word2vev\n",
    "\n",
    "    \n",
    "3. Bernoulli naive bayes:\n",
    "    It is used for binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15b655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Real-world applications:\n",
    "\n",
    "1.spam detection- to classify if mail is spam or not\n",
    "2.sentiment analysis- If a review is positive negative or neutral\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec6849ce",
   "metadata": {},
   "source": [
    "                         P(Features∣Class)×P(Class)\n",
    ">> P(Class∣Features) =  --------------------------------\n",
    "                            P(Features)\n",
    "\n",
    "\n",
    ">> P(Class∣Features): This is what we want to find! It's the Posterior Probability – the probability of our \"Class\" (e.g., \"Spam\") given the \"Features\" (e.g., words in the email). This is our final prediction\n",
    " \n",
    ">> P(Features∣Class): This is the Likelihood. It's the probability of seeing these \"Features\" if a certain \"Class\" is true (e.g., \"What's the probability of seeing 'free' and 'money' if the email is Spam?\"). This is calculated from our training data.\n",
    "\n",
    ">> P(Class): This is the Prior Probability – the initial probability of a \"Class\" being true, before we even look at the features (e.g., \"What's the overall probability that any email is Spam?\"). This is simply the proportion of that class in our training data.\n",
    "    \n",
    ">> P(Features): This is the Evidence – the probability of seeing these specific \"Features\" at all. For classification, this term often becomes a constant for all classes, so we often ignore it when just comparing which class is most likely. We mainly care about the top part of the formula."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
